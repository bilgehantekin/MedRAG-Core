"""
Medical Chatbot - FastAPI Backend
SaÄŸlÄ±k odaklÄ± chatbot API'si - Groq + Translation Pipeline
TR â†’ EN â†’ LLM â†’ EN â†’ TR
"""

from contextlib import asynccontextmanager
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from typing import Optional, List
import os
from pathlib import Path
from dotenv import load_dotenv

# .env dosyasÄ±nÄ± backend dizininden yÃ¼kle
env_path = Path(__file__).parent.parent / ".env"
load_dotenv(dotenv_path=env_path)

from groq import Groq
from deep_translator import GoogleTranslator

from app.health_filter import is_health_related, check_emergency_symptoms, is_non_health_topic, is_greeting, get_greeting_type, count_health_signals, count_non_health_signals
from app.prompts import get_system_prompt, format_response_prompt, get_greeting_response
from app.medicines import MEDICINE_BRANDS
from app.medicine_utils import detect_medicines, mask_medicines, unmask_medicines, convert_english_medicines_to_turkish
from app.domain import check_health_domain_simple

# Groq API ayarlarÄ±
GROQ_API_KEY = os.getenv("GROQ_API_KEY", "")
GROQ_MODEL = os.getenv("GROQ_MODEL", "llama-3.3-70b-versatile")

if not GROQ_API_KEY:
    print("âš ï¸  UYARI: GROQ_API_KEY ayarlanmamÄ±ÅŸ! .env dosyasÄ±na ekleyin.")

groq_client = Groq(api_key=GROQ_API_KEY)

# Translator'lar
tr_to_en = GoogleTranslator(source='tr', target='en')
en_to_tr = GoogleTranslator(source='en', target='tr')


@asynccontextmanager
async def lifespan(app: FastAPI):
    """Application lifespan events - preload models at startup"""
    # Startup: preload X-ray model if not in demo mode
    try:
        from app.image.config import DEMO_MODE
        if not DEMO_MODE:
            print("ğŸ”„ Pre-loading X-ray analysis model at startup...")
            from app.image import inference
            if inference.load_model():
                print("âœ… X-ray model pre-loaded successfully")
            else:
                print("âš ï¸ X-ray model failed to pre-load, will use DEMO mode")
        else:
            print("â„¹ï¸ X-ray model in DEMO mode - skipping pre-load")
    except ImportError as e:
        print(f"âš ï¸ Image module not available: {e}")
    except Exception as e:
        print(f"âš ï¸ Error pre-loading model: {e}")

    yield  # Application runs here

    # Shutdown: cleanup if needed
    print("ğŸ‘‹ Shutting down...")


app = FastAPI(
    title="Medical Chatbot API",
    description="SaÄŸlÄ±k odaklÄ± bilgilendirme chatbot'u - Groq + Translation + RAG",
    version="3.0.0",
    lifespan=lifespan
)

# RAG Router'Ä± dahil et (opsiyonel - RAG kuruluysa)
try:
    from app.rag.router import router as rag_router
    app.include_router(rag_router)
    print("âœ… RAG router yÃ¼klendi - /rag/* endpoint'leri aktif")
except ImportError as e:
    print(f"âš ï¸ RAG router yÃ¼klenemedi (sentence-transformers/faiss kurulu deÄŸil): {e}")

# Image Analysis Router'Ä± dahil et (opsiyonel - torch kuruluysa)
try:
    from app.image.router import router as image_router
    app.include_router(image_router)
    print("âœ… Image Analysis router yÃ¼klendi - /image/* endpoint'leri aktif")
except ImportError as e:
    print(f"âš ï¸ Image Analysis router yÃ¼klenemedi (torch/torchxrayvision kurulu deÄŸil): {e}")

# CORS ayarlarÄ±
# NOT: Prod'da allow_origins'i whitelist'e Ã§evirin veya allow_credentials=False yapÄ±n
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=False,  # "*" ile kullanÄ±ldÄ±ÄŸÄ±nda False olmalÄ±
    allow_methods=["*"],
    allow_headers=["*"],
)


class Message(BaseModel):
    role: str  # "user" veya "assistant"
    content: str
    content_en: Optional[str] = None  # Ä°ngilizce versiyon (drift Ã¶nleme iÃ§in)


class SymptomContext(BaseModel):
    """3D modelden gelen yapÄ±landÄ±rÄ±lmÄ±ÅŸ semptom bilgisi"""
    region: str  # Ã¶rn: "left_shin"
    region_name_tr: str  # Ã¶rn: "Sol Kaval KemiÄŸi"
    region_name_en: str  # Ã¶rn: "Left Shin (Tibia)"
    symptom: str  # Ã¶rn: "pain"
    symptom_name_tr: str  # Ã¶rn: "AÄŸrÄ±"
    symptom_name_en: str  # Ã¶rn: "Pain"
    severity_0_10: int
    onset: str  # Ã¶rn: "2_3_days"
    trigger: Optional[str] = None  # Ã¶rn: "after_running"
    red_flags: List[str] = Field(default_factory=list)


class ChatRequest(BaseModel):
    message: str
    history: List[Message] = Field(default_factory=list)
    detailed_response: bool = False
    symptom_context: Optional[SymptomContext] = None  # 3D modelden gelen yapÄ±sal bilgi


class ChatResponse(BaseModel):
    response: str
    response_en: Optional[str] = None  # Ä°ngilizce versiyon (drift Ã¶nleme iÃ§in frontend'in saklamasÄ± iÃ§in)
    is_emergency: bool = False
    disclaimer: str = "âš ï¸ Bu bilgiler eÄŸitim amaÃ§lÄ±dÄ±r, tÄ±bbi tavsiye deÄŸildir. Acil durumlarda 112'yi arayÄ±n."

def translate_to_english(text: str) -> str:
    """TÃ¼rkÃ§e metni Ä°ngilizce'ye Ã§evirir (ilaÃ§ maskeleri korunur)"""
    try:
        translated = tr_to_en.translate(text)
        print(f"[TRâ†’EN] {text[:50]}... â†’ {translated[:50]}...")
        return translated
    except Exception as e:
        print(f"[ERROR] Ã‡eviri hatasÄ± (TRâ†’EN): {e}")
        return text  # Hata durumunda orijinal metni dÃ¶ndÃ¼r


def translate_to_turkish(text: str) -> str:
    """Ä°ngilizce metni TÃ¼rkÃ§e'ye Ã§evirir"""
    try:
        translated = en_to_tr.translate(text)
        print(f"[ENâ†’TR] {text[:50]}... â†’ {translated[:50]}...")
        return translated
    except Exception as e:
        print(f"[ERROR] Ã‡eviri hatasÄ± (ENâ†’TR): {e}")
        return text


def call_groq(messages: list, system_prompt: str = None) -> str:
    """Groq API'sine istek gÃ¶nderir (Ä°ngilizce)"""
    try:
        groq_messages = []
        
        if system_prompt:
            groq_messages.append({"role": "system", "content": system_prompt})
        
        for msg in messages:
            groq_messages.append({"role": msg["role"], "content": msg["content"]})
        
        print(f"[DEBUG] Groq'a istek gÃ¶nderiliyor, model: {GROQ_MODEL}")
        
        response = groq_client.chat.completions.create(
            model=GROQ_MODEL,
            messages=groq_messages,
            temperature=0.7,
            max_tokens=2048,
        )
        
        result = response.choices[0].message.content
        print(f"[DEBUG] Groq yanÄ±tÄ±: {result[:100]}...")
        return result
        
    except Exception as e:
        print(f"[ERROR] Groq hatasÄ±: {str(e)}")
        raise HTTPException(status_code=503, detail=f"LLM API hatasÄ±: {str(e)}")


def call_groq_classifier(messages: list, system_prompt: str) -> str:
    """
    SÄ±nÄ±flandÄ±rma iÃ§in optimize edilmiÅŸ Groq Ã§aÄŸrÄ±sÄ±.
    - temperature=0 (deterministik)
    - max_tokens=3 (YES/NO/UNCERTAIN)
    - stop=["\n"] (tek satÄ±r yanÄ±t)
    """
    try:
        groq_messages = [{"role": "system", "content": system_prompt}]
        
        for msg in messages:
            groq_messages.append({"role": msg["role"], "content": msg["content"]})
        
        print(f"[CLASSIFIER] Groq'a sÄ±nÄ±flandÄ±rma isteÄŸi gÃ¶nderiliyor")
        
        response = groq_client.chat.completions.create(
            model=GROQ_MODEL,
            messages=groq_messages,
            temperature=0,  # Deterministik
            max_tokens=3,   # KÄ±sa yanÄ±t (YES/NO/UNCERTAIN)
            stop=["\n"],    # Tek satÄ±r
        )
        
        result = response.choices[0].message.content.strip().upper()
        print(f"[CLASSIFIER] SonuÃ§: {result}")
        return result
        
    except Exception as e:
        print(f"[ERROR] Classifier hatasÄ±: {str(e)}")
        return "UNCERTAIN"  # Hata durumunda belirsiz





def get_english_system_prompt(detailed: bool = False, has_history: bool = False, symptom_context: SymptomContext = None) -> str:
    """Ä°ngilizce sistem prompt'u dÃ¶ndÃ¼rÃ¼r - ilk soru vs takip sorularÄ± iÃ§in farklÄ±
    
    EÄŸer symptom_context varsa, 3D modelden gelen yapÄ±sal bilgiyi prompt'a ekler.
    """
    
    # YapÄ±sal context varsa, prompt'a ekle
    context_section = ""
    if symptom_context:
        context_section = f"""
=== STRUCTURED SYMPTOM DATA FROM 3D BODY MODEL ===
The user has selected the following through the interactive 3D human body interface:

BODY REGION: {symptom_context.region_name_en} ({symptom_context.region})
SYMPTOM TYPE: {symptom_context.symptom_name_en} ({symptom_context.symptom})
SEVERITY: {symptom_context.severity_0_10}/10
ONSET: {symptom_context.onset}
TRIGGER: {symptom_context.trigger or 'Not specified'}
RED FLAGS REPORTED: {', '.join(symptom_context.red_flags) if symptom_context.red_flags else 'None'}

Use this structured data to provide more accurate and targeted guidance.
Focus on the specific body region and symptom type.
If red flags are present, emphasize seeking immediate medical attention.
=================================================

"""
    
    if not has_history:
        # Ä°LK SORU - KapsamlÄ± yanÄ±t
        return context_section + """You are a medical health assistant. Your role is to provide health education and general guidance.

IMPORTANT: This is the user's FIRST question. Provide a COMPREHENSIVE response with this EXACT structure:

**Your concern:** [1-2 sentence acknowledgment and brief explanation]

**Possible Causes:**
â€¢ [Cause 1]
â€¢ [Cause 2]
â€¢ [Cause 3]
â€¢ [Cause 4]

**What You Can Do:**
â€¢ [Recommendation 1]
â€¢ [Recommendation 2]
â€¢ [Recommendation 3]
â€¢ [Recommendation 4]

**Questions for You:**
â€¢ [Question about duration]
â€¢ [Question about severity]
â€¢ [Question about other symptoms]

**âš ï¸ Warning Signs - See a Doctor If:**
â€¢ [Red flag 1]
â€¢ [Red flag 2]
â€¢ [Red flag 3]
â€¢ [Red flag 4]

FORMATTING RULES:
- ALWAYS use bullet points (â€¢) for lists - NEVER write as paragraphs
- Use **bold** for section headers
- Keep each bullet point to 1-2 sentences max
- Be empathetic but concise
- Do NOT diagnose or prescribe
- You are NOT a doctor"""
    
    else:
        # TAKÄ°P SORUSU - OdaklÄ± yanÄ±t
        return context_section + """You are a medical health assistant continuing a conversation.

IMPORTANT: This is a FOLLOW-UP question. Be CONCISE and FOCUSED.

**Response Format:**
- Start with a direct answer to their question
- Use bullet points when listing multiple items:
  â€¢ Point 1
  â€¢ Point 2
- Keep response to 3-5 bullet points or 2-3 short paragraphs
- Don't repeat information already given

**If they share new symptoms:**
â€¢ Acknowledge the new info briefly
â€¢ Adjust guidance if needed
â€¢ Mention if urgency changes

RULES:
- You are NOT a doctor
- Be concise - this is a follow-up, not a new consultation
- Use bullet points (â€¢) for any lists
- Stay focused on their current question"""


@app.get("/")
async def root():
    return {"message": "Medical Chatbot API", "status": "active", "provider": "Groq + Translation"}


def has_health_context_in_history(history: list) -> bool:
    """
    History'de gerÃ§ek bir saÄŸlÄ±k konusu var mÄ± kontrol eder.
    Sadece selamlaÅŸma/nasÄ±lsÄ±n gibi mesajlar varsa False dÃ¶ner.
    """
    if not history:
        return False
    
    for msg in history:
        if msg.role == "user":
            content = msg.content.lower()
            # SelamlaÅŸma deÄŸilse ve saÄŸlÄ±k keyword'Ã¼ iÃ§eriyorsa
            if not is_greeting(content) and is_health_related(content):
                return True
    
    return False


@app.get("/health")
async def health_check():
    return {"status": "healthy"}


@app.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """
    Ana chat endpoint'i
    Pipeline: TR Soru â†’ EN Ã‡eviri â†’ Groq LLM â†’ TR Ã‡eviri â†’ YanÄ±t
    """
    user_message = request.message.strip()
    
    if not user_message:
        raise HTTPException(status_code=400, detail="Mesaj boÅŸ olamaz")
    
    has_history = len(request.history) > 0
    # SaÄŸlÄ±k konulu bir geÃ§miÅŸ var mÄ±? (merhaba/nasÄ±lsÄ±n deÄŸil, gerÃ§ek saÄŸlÄ±k sorusu)
    has_health_context = has_health_context_in_history(request.history)
    
    # Symptom context var mÄ±? (3D modelden gelen yapÄ±sal bilgi)
    has_symptom_context = request.symptom_context is not None
    
    # 1. SelamlaÅŸma kontrolÃ¼ (TÃ¼rkÃ§e)
    # SADECE symptom_context YOKSA ve saÄŸlÄ±k baÄŸlamÄ± YOKSA selamlaÅŸma yanÄ±tÄ± ver
    greeting_type = get_greeting_type(user_message)
    if greeting_type and not has_health_context and not has_symptom_context:
        return ChatResponse(
            response=get_greeting_response(greeting_type),
            is_emergency=False
        )
    
    # 2. Acil durum kontrolÃ¼ (TÃ¼rkÃ§e + YapÄ±sal context)
    # Red flag'leri kontrol et (yapÄ±sal context'ten)
    if request.symptom_context and request.symptom_context.red_flags:
        critical_flags = ['loss_of_consciousness', 'difficulty_breathing', 'chest_pain', 'severe_bleeding']
        if any(flag in critical_flags for flag in request.symptom_context.red_flags):
            return ChatResponse(
                response=f"ğŸš¨ **ACÄ°L DURUM UYARISI** ğŸš¨\n\nBildirdiÄŸiniz belirtiler ({request.symptom_context.region_name_tr} - {request.symptom_context.symptom_name_tr}) acil tÄ±bbi mÃ¼dahale gerektirebilir!\n\n**HEMEN 112'yi arayÄ±n veya en yakÄ±n acil servise gidin!**\n\nâš ï¸ Bu durumu ciddiye alÄ±n ve beklemeden profesyonel yardÄ±m alÄ±n.",
                is_emergency=True,
                disclaimer="ğŸš¨ ACÄ°L DURUM - Hemen 112'yi arayÄ±n!"
            )
    
    is_emergency, emergency_response = check_emergency_symptoms(user_message)
    if is_emergency:
        return ChatResponse(
            response=emergency_response,
            is_emergency=True,
            disclaimer="ğŸš¨ ACÄ°L DURUM - Hemen 112'yi arayÄ±n!"
        )
    
    # 3. SaÄŸlÄ±k domain kontrolÃ¼
    # EÄŸer symptom_context varsa, otomatik olarak saÄŸlÄ±k konusu kabul et
    # - Ä°lk saÄŸlÄ±k sorusu: tam saÄŸlÄ±k kontrolÃ¼ yap
    # - Follow-up'larda: sadece aÃ§Ä±kÃ§a alakasÄ±z konularÄ± reddet (kara delik, yemek tarifi vs.)
    #   "gelip geÃ§ici", "evet", "3 gÃ¼ndÃ¼r" gibi kÄ±sa cevaplar kabul edilir
    has_symptom_context = request.symptom_context is not None
    
    if not is_greeting(user_message) and not has_symptom_context:
        if has_health_context:
            # Follow-up: sadece aÃ§Ä±kÃ§a saÄŸlÄ±k dÄ±ÅŸÄ± konu deÄŸiÅŸikliÄŸini reddet
            # Ama Ã¶nce saÄŸlÄ±k sinyali var mÄ± kontrol et (Ã¶rn: "dizim aÄŸrÄ±yor ama futbol")
            health_kw, health_pat, _, _ = count_health_signals(user_message)
            hard_nh, soft_nh, _, _ = count_non_health_signals(user_message)
            
            # SaÄŸlÄ±k sinyali varsa geÃ§ir
            if health_kw + health_pat > 0:
                pass  # Devam et
            # Follow-up'ta sadece HARD konu deÄŸiÅŸimini reddet
            elif hard_nh > 0:
                return ChatResponse(
                    response="AnladÄ±m, konu deÄŸiÅŸtirmek istiyorsunuz. ğŸ˜Š\n\nAncak ben sadece saÄŸlÄ±k konularÄ±nda yardÄ±mcÄ± olabiliyorum. EÄŸer saÄŸlÄ±kla ilgili baÅŸka bir sorunuz varsa, sormaktan Ã§ekinmeyin!\n\nÃ–nceki konuya devam etmek isterseniz de yanÄ±nÄ±zdayÄ±m.",
                    is_emergency=False
                )
            # Soft non-health (fiyat/ne kadar/futbol) gÃ¶rdÃ¼ysen bile follow-up'ta direkt reddetme
            else:
                pass  # Devam et
        else:
            # Ä°lk saÄŸlÄ±k sorusu (veya sadece selamlaÅŸma geÃ§miÅŸi var): tam saÄŸlÄ±k kontrolÃ¼
            domain_result = check_health_domain_simple(user_message)
            
            if domain_result == "NO":
                return ChatResponse(
                    response="Merhaba! Ben saÄŸlÄ±k odaklÄ± bir asistanÄ±m. ğŸ¥\n\nSadece saÄŸlÄ±k, hastalÄ±k, semptom ve tedavi ile ilgili sorularÄ±nÄ±zda size yardÄ±mcÄ± olabilirim. SaÄŸlÄ±k dÄ±ÅŸÄ± konularda maalesef yardÄ±mcÄ± olamÄ±yorum.\n\nSaÄŸlÄ±kla ilgili bir sorunuz varsa, lÃ¼tfen sorun!",
                    is_emergency=False
                )
            elif domain_result == "UNCERTAIN":
                # Belirsiz durumda netleÅŸtirme sorusu sor
                return ChatResponse(
                    response="Merhaba! ğŸ˜Š MesajÄ±nÄ±zÄ± tam anlayamadÄ±m.\n\nBen saÄŸlÄ±k konularÄ±nda yardÄ±mcÄ± olan bir asistanÄ±m. SaÄŸlÄ±k, semptom veya ilaÃ§larla ilgili bir sorunuz mu var?\n\nLÃ¼tfen sorunuzu biraz daha aÃ§Ä±klayabilir misiniz?",
                    is_emergency=False
                )
    
    # 4. Pipeline: TR â†’ MASK â†’ EN â†’ LLM â†’ TR â†’ UNMASK â†’ ENâ†’TR
    # Ä°laÃ§ isimlerini maskele, Ã§evir, LLM'den yanÄ±t al, Ã§evir, maskeleri aÃ§, EN ilaÃ§larÄ± TR'ye Ã§evir

    # Global mask_map ve counter (history + current message iÃ§in tek map)
    global_mask_map = {}
    mask_counter = 0

    # 4a. GeÃ§miÅŸ mesajlarÄ± iÅŸle (history'den baÅŸla, counter collision Ã¶nleme)
    messages_en = []
    for msg in request.history[-10:]:
        if msg.content_en:
            # Frontend'den gelen Ä°ngilizce versiyon var, direkt kullan (drift Ã¶nleme)
            content_en = msg.content_en
        elif msg.role == "user":
            # User mesajÄ±, maskele ve Ã§evir (counter devam ettir)
            masked_hist, global_mask_map, mask_counter = mask_medicines(
                msg.content, start_counter=mask_counter, existing_mask_map=global_mask_map
            )
            content_en = translate_to_english(masked_hist)
        else:
            # Assistant mesajÄ± ve content_en yok, Ã§evir (eski mesajlar iÃ§in backward compat)
            content_en = translate_to_english(msg.content)

        messages_en.append({"role": msg.role, "content": content_en})

    # 4b. KullanÄ±cÄ± mesajÄ±ndaki ilaÃ§larÄ± maskele (counter kaldÄ±ÄŸÄ± yerden devam)
    masked_message, global_mask_map, mask_counter = mask_medicines(
        user_message, start_counter=mask_counter, existing_mask_map=global_mask_map
    )
    print(f"[MASK-MAP] {global_mask_map}")

    # 4c. MaskelenmiÅŸ mesajÄ± Ä°ngilizce'ye Ã§evir
    user_message_en = translate_to_english(masked_message)

    # KullanÄ±cÄ± mesajÄ±nÄ± ekle
    messages_en.append({"role": "user", "content": user_message_en})

    # 4d. Ä°ngilizce sistem prompt'u al (yapÄ±sal context ile)
    # has_health_context: True ise follow-up (kÄ±sa), False ise ilk saÄŸlÄ±k sorusu (detaylÄ±)
    system_prompt_en = get_english_system_prompt(
        detailed=request.detailed_response,
        has_history=has_health_context,
        symptom_context=request.symptom_context
    )

    # 4e. Groq'tan Ä°ngilizce yanÄ±t al
    response_en_raw = call_groq(messages_en, system_prompt=system_prompt_en)

    # 4f. YanÄ±tÄ± TÃ¼rkÃ§e'ye Ã§evir
    response_tr = translate_to_turkish(response_en_raw)

    # 4g. Ã–NCE LLM'in kendi eklediÄŸi Ä°ngilizce ilaÃ§ isimlerini TÃ¼rkÃ§e'ye Ã§evir
    # (mask ile yakalanmayan "ibuprofen", "acetaminophen" gibi)
    # NOT: Bu unmask'ten Ã–NCE yapÄ±lmalÄ±, yoksa Ã§ift dÃ¶nÃ¼ÅŸÃ¼m olur
    response_tr = convert_english_medicines_to_turkish(response_tr, format_style="tr_with_en")

    # 4h. SONRA maskeleri aÃ§: MEDTOK0 â†’ "Parol (paracetamol)"
    if global_mask_map:
        response_tr = unmask_medicines(response_tr, global_mask_map, format_style="tr_with_en")
        # response_en iÃ§in en_only kullan (drift Ã¶nleme - saf Ä°ngilizce kalmalÄ±)
        response_en_raw = unmask_medicines(response_en_raw, global_mask_map, format_style="en_only")

    return ChatResponse(
        response=response_tr,
        response_en=response_en_raw,  # Saf Ä°ngilizce (drift Ã¶nleme iÃ§in)
        is_emergency=False
    )


@app.get("/models")
async def list_models():
    return {
        "current_model": GROQ_MODEL,
        "available_models": [
            "llama-3.3-70b-versatile",
            "llama-3.1-70b-versatile", 
            "mixtral-8x7b-32768"
        ],
        "provider": "Groq",
        "pipeline": "TR â†’ EN â†’ LLM â†’ TR"
    }


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
