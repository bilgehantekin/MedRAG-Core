"""
Medical Chatbot - FastAPI Backend
SaÄŸlÄ±k odaklÄ± chatbot API'si - Groq + Translation Pipeline
TR â†’ EN â†’ LLM â†’ EN â†’ TR
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional, List
import os
from dotenv import load_dotenv

# .env dosyasÄ±nÄ± yÃ¼kle
load_dotenv()

from groq import Groq
from deep_translator import GoogleTranslator

from app.health_filter import is_health_related, check_emergency_symptoms, is_non_health_topic, is_greeting, get_greeting_type
from app.prompts import get_system_prompt, format_response_prompt, get_greeting_response

# Groq API ayarlarÄ±
GROQ_API_KEY = os.getenv("GROQ_API_KEY", "")
GROQ_MODEL = os.getenv("GROQ_MODEL", "llama-3.3-70b-versatile")

if not GROQ_API_KEY:
    print("âš ï¸  UYARI: GROQ_API_KEY ayarlanmamÄ±ÅŸ! .env dosyasÄ±na ekleyin.")

groq_client = Groq(api_key=GROQ_API_KEY)

# Translator'lar
tr_to_en = GoogleTranslator(source='tr', target='en')
en_to_tr = GoogleTranslator(source='en', target='tr')

app = FastAPI(
    title="Medical Chatbot API",
    description="SaÄŸlÄ±k odaklÄ± bilgilendirme chatbot'u - Groq + Translation",
    version="2.0.0"
)

# CORS ayarlarÄ±
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


class Message(BaseModel):
    role: str  # "user" veya "assistant"
    content: str


class SymptomContext(BaseModel):
    """3D modelden gelen yapÄ±landÄ±rÄ±lmÄ±ÅŸ semptom bilgisi"""
    region: str  # Ã¶rn: "left_shin"
    region_name_tr: str  # Ã¶rn: "Sol Kaval KemiÄŸi"
    region_name_en: str  # Ã¶rn: "Left Shin (Tibia)"
    symptom: str  # Ã¶rn: "pain"
    symptom_name_tr: str  # Ã¶rn: "AÄŸrÄ±"
    symptom_name_en: str  # Ã¶rn: "Pain"
    severity_0_10: int
    onset: str  # Ã¶rn: "2_3_days"
    trigger: Optional[str] = None  # Ã¶rn: "after_running"
    red_flags: Optional[List[str]] = []


class ChatRequest(BaseModel):
    message: str
    history: Optional[List[Message]] = []
    detailed_response: Optional[bool] = False
    symptom_context: Optional[SymptomContext] = None  # 3D modelden gelen yapÄ±sal bilgi


class ChatResponse(BaseModel):
    response: str
    is_emergency: bool = False
    disclaimer: str = "âš ï¸ Bu bilgiler eÄŸitim amaÃ§lÄ±dÄ±r, tÄ±bbi tavsiye deÄŸildir. Acil durumlarda 112'yi arayÄ±n."


def translate_to_english(text: str) -> str:
    """TÃ¼rkÃ§e metni Ä°ngilizce'ye Ã§evirir"""
    try:
        translated = tr_to_en.translate(text)
        print(f"[TRâ†’EN] {text[:50]}... â†’ {translated[:50]}...")
        return translated
    except Exception as e:
        print(f"[ERROR] Ã‡eviri hatasÄ± (TRâ†’EN): {e}")
        return text  # Hata durumunda orijinal metni dÃ¶ndÃ¼r


def translate_to_turkish(text: str) -> str:
    """Ä°ngilizce metni TÃ¼rkÃ§e'ye Ã§evirir"""
    try:
        translated = en_to_tr.translate(text)
        print(f"[ENâ†’TR] {text[:50]}... â†’ {translated[:50]}...")
        return translated
    except Exception as e:
        print(f"[ERROR] Ã‡eviri hatasÄ± (ENâ†’TR): {e}")
        return text


def call_groq(messages: list, system_prompt: str = None) -> str:
    """Groq API'sine istek gÃ¶nderir (Ä°ngilizce)"""
    try:
        groq_messages = []
        
        if system_prompt:
            groq_messages.append({"role": "system", "content": system_prompt})
        
        for msg in messages:
            groq_messages.append({"role": msg["role"], "content": msg["content"]})
        
        print(f"[DEBUG] Groq'a istek gÃ¶nderiliyor, model: {GROQ_MODEL}")
        
        response = groq_client.chat.completions.create(
            model=GROQ_MODEL,
            messages=groq_messages,
            temperature=0.7,
            max_tokens=2048,
        )
        
        result = response.choices[0].message.content
        print(f"[DEBUG] Groq yanÄ±tÄ±: {result[:100]}...")
        return result
        
    except Exception as e:
        print(f"[ERROR] Groq hatasÄ±: {str(e)}")
        raise HTTPException(status_code=503, detail=f"LLM API hatasÄ±: {str(e)}")





def check_health_domain_simple(message: str) -> bool:
    """MesajÄ±n saÄŸlÄ±kla ilgili olup olmadÄ±ÄŸÄ±nÄ± basit kontrol eder"""
    # Ã–nce saÄŸlÄ±k DIÅI keyword kontrolÃ¼
    if is_non_health_topic(message):
        return False
    
    # Keyword bazlÄ± saÄŸlÄ±k kontrolÃ¼
    if is_health_related(message):
        return True
    
    # Belirsiz durumda LLM'e sor (Ä°ngilizce)
    message_en = translate_to_english(message)
    
    check_messages = [{
        "role": "user", 
        "content": f"Is this message about MEDICAL/HEALTH topics? Answer only YES or NO.\n\nMessage: {message_en}"
    }]
    
    check_system = """You are a classifier. Determine if the message is about medical/health topics.

HEALTH TOPICS (YES): diseases, symptoms, medications, treatments, body functions, doctors, hospitals, mental health

NON-HEALTH TOPICS (NO): recipes, sports, technology, weather, movies, travel, politics, general chat

Answer only YES or NO. If unsure, answer NO."""
    
    try:
        result = call_groq(check_messages, system_prompt=check_system)
        return "YES" in result.upper() and "NO" not in result.upper()
    except:
        return False


def get_english_system_prompt(detailed: bool = False, has_history: bool = False, symptom_context: SymptomContext = None) -> str:
    """Ä°ngilizce sistem prompt'u dÃ¶ndÃ¼rÃ¼r - ilk soru vs takip sorularÄ± iÃ§in farklÄ±
    
    EÄŸer symptom_context varsa, 3D modelden gelen yapÄ±sal bilgiyi prompt'a ekler.
    """
    
    # YapÄ±sal context varsa, prompt'a ekle
    context_section = ""
    if symptom_context:
        context_section = f"""
=== STRUCTURED SYMPTOM DATA FROM 3D BODY MODEL ===
The user has selected the following through the interactive 3D human body interface:

BODY REGION: {symptom_context.region_name_en} ({symptom_context.region})
SYMPTOM TYPE: {symptom_context.symptom_name_en} ({symptom_context.symptom})
SEVERITY: {symptom_context.severity_0_10}/10
ONSET: {symptom_context.onset}
TRIGGER: {symptom_context.trigger or 'Not specified'}
RED FLAGS REPORTED: {', '.join(symptom_context.red_flags) if symptom_context.red_flags else 'None'}

Use this structured data to provide more accurate and targeted guidance.
Focus on the specific body region and symptom type.
If red flags are present, emphasize seeking immediate medical attention.
=================================================

"""
    
    if not has_history:
        # Ä°LK SORU - KapsamlÄ± yanÄ±t
        return context_section + """You are a medical health assistant. Your role is to provide health education and general guidance.

IMPORTANT: This is the user's FIRST question. Provide a COMPREHENSIVE response with this EXACT structure:

**Your concern:** [1-2 sentence acknowledgment and brief explanation]

**Possible Causes:**
â€¢ [Cause 1]
â€¢ [Cause 2]
â€¢ [Cause 3]
â€¢ [Cause 4]

**What You Can Do:**
â€¢ [Recommendation 1]
â€¢ [Recommendation 2]
â€¢ [Recommendation 3]
â€¢ [Recommendation 4]

**Questions for You:**
â€¢ [Question about duration]
â€¢ [Question about severity]
â€¢ [Question about other symptoms]

**âš ï¸ Warning Signs - See a Doctor If:**
â€¢ [Red flag 1]
â€¢ [Red flag 2]
â€¢ [Red flag 3]
â€¢ [Red flag 4]

FORMATTING RULES:
- ALWAYS use bullet points (â€¢) for lists - NEVER write as paragraphs
- Use **bold** for section headers
- Keep each bullet point to 1-2 sentences max
- Be empathetic but concise
- Do NOT diagnose or prescribe
- You are NOT a doctor"""
    
    else:
        # TAKÄ°P SORUSU - OdaklÄ± yanÄ±t
        return context_section + """You are a medical health assistant continuing a conversation.

IMPORTANT: This is a FOLLOW-UP question. Be CONCISE and FOCUSED.

**Response Format:**
- Start with a direct answer to their question
- Use bullet points when listing multiple items:
  â€¢ Point 1
  â€¢ Point 2
- Keep response to 3-5 bullet points or 2-3 short paragraphs
- Don't repeat information already given

**If they share new symptoms:**
â€¢ Acknowledge the new info briefly
â€¢ Adjust guidance if needed
â€¢ Mention if urgency changes

RULES:
- You are NOT a doctor
- Be concise - this is a follow-up, not a new consultation
- Use bullet points (â€¢) for any lists
- Stay focused on their current question"""


@app.get("/")
async def root():
    return {"message": "Medical Chatbot API", "status": "active", "provider": "Groq + Translation"}


def has_health_context_in_history(history: list) -> bool:
    """
    History'de gerÃ§ek bir saÄŸlÄ±k konusu var mÄ± kontrol eder.
    Sadece selamlaÅŸma/nasÄ±lsÄ±n gibi mesajlar varsa False dÃ¶ner.
    """
    if not history:
        return False
    
    for msg in history:
        if msg.role == "user":
            content = msg.content.lower()
            # SelamlaÅŸma deÄŸilse ve saÄŸlÄ±k keyword'Ã¼ iÃ§eriyorsa
            if not is_greeting(content) and is_health_related(content):
                return True
    
    return False


@app.get("/health")
async def health_check():
    return {"status": "healthy"}


@app.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """
    Ana chat endpoint'i
    Pipeline: TR Soru â†’ EN Ã‡eviri â†’ Groq LLM â†’ TR Ã‡eviri â†’ YanÄ±t
    """
    user_message = request.message.strip()
    
    if not user_message:
        raise HTTPException(status_code=400, detail="Mesaj boÅŸ olamaz")
    
    has_history = len(request.history) > 0
    # SaÄŸlÄ±k konulu bir geÃ§miÅŸ var mÄ±? (merhaba/nasÄ±lsÄ±n deÄŸil, gerÃ§ek saÄŸlÄ±k sorusu)
    has_health_context = has_health_context_in_history(request.history)
    
    # 1. SelamlaÅŸma kontrolÃ¼ (TÃ¼rkÃ§e)
    greeting_type = get_greeting_type(user_message)
    if greeting_type and not has_health_context:
        return ChatResponse(
            response=get_greeting_response(greeting_type),
            is_emergency=False
        )
    
    # 2. Acil durum kontrolÃ¼ (TÃ¼rkÃ§e + YapÄ±sal context)
    # Red flag'leri kontrol et (yapÄ±sal context'ten)
    if request.symptom_context and request.symptom_context.red_flags:
        critical_flags = ['loss_of_consciousness', 'difficulty_breathing', 'chest_pain', 'severe_bleeding']
        if any(flag in critical_flags for flag in request.symptom_context.red_flags):
            return ChatResponse(
                response=f"ğŸš¨ **ACÄ°L DURUM UYARISI** ğŸš¨\n\nBildirdiÄŸiniz belirtiler ({request.symptom_context.region_name_tr} - {request.symptom_context.symptom_name_tr}) acil tÄ±bbi mÃ¼dahale gerektirebilir!\n\n**HEMEN 112'yi arayÄ±n veya en yakÄ±n acil servise gidin!**\n\nâš ï¸ Bu durumu ciddiye alÄ±n ve beklemeden profesyonel yardÄ±m alÄ±n.",
                is_emergency=True,
                disclaimer="ğŸš¨ ACÄ°L DURUM - Hemen 112'yi arayÄ±n!"
            )
    
    is_emergency, emergency_response = check_emergency_symptoms(user_message)
    if is_emergency:
        return ChatResponse(
            response=emergency_response,
            is_emergency=True,
            disclaimer="ğŸš¨ ACÄ°L DURUM - Hemen 112'yi arayÄ±n!"
        )
    
    # 3. SaÄŸlÄ±k domain kontrolÃ¼
    # EÄŸer symptom_context varsa, otomatik olarak saÄŸlÄ±k konusu kabul et
    # - Ä°lk saÄŸlÄ±k sorusu: tam saÄŸlÄ±k kontrolÃ¼ yap
    # - Follow-up'larda: sadece aÃ§Ä±kÃ§a alakasÄ±z konularÄ± reddet (kara delik, yemek tarifi vs.)
    #   "gelip geÃ§ici", "evet", "3 gÃ¼ndÃ¼r" gibi kÄ±sa cevaplar kabul edilir
    has_symptom_context = request.symptom_context is not None
    
    if not is_greeting(user_message) and not has_symptom_context:
        if has_health_context:
            # Follow-up: sadece aÃ§Ä±kÃ§a saÄŸlÄ±k dÄ±ÅŸÄ± konu deÄŸiÅŸikliÄŸini reddet
            if is_non_health_topic(user_message):
                return ChatResponse(
                    response="AnladÄ±m, konu deÄŸiÅŸtirmek istiyorsunuz. ğŸ˜Š\n\nAncak ben sadece saÄŸlÄ±k konularÄ±nda yardÄ±mcÄ± olabiliyorum. EÄŸer saÄŸlÄ±kla ilgili baÅŸka bir sorunuz varsa, sormaktan Ã§ekinmeyin!\n\nÃ–nceki konuya devam etmek isterseniz de yanÄ±nÄ±zdayÄ±m.",
                    is_emergency=False
                )
        else:
            # Ä°lk saÄŸlÄ±k sorusu (veya sadece selamlaÅŸma geÃ§miÅŸi var): tam saÄŸlÄ±k kontrolÃ¼
            is_health = check_health_domain_simple(user_message)
            if not is_health:
                return ChatResponse(
                    response="Merhaba! Ben saÄŸlÄ±k odaklÄ± bir asistanÄ±m. ğŸ¥\n\nSadece saÄŸlÄ±k, hastalÄ±k, semptom ve tedavi ile ilgili sorularÄ±nÄ±zda size yardÄ±mcÄ± olabilirim. SaÄŸlÄ±k dÄ±ÅŸÄ± konularda maalesef yardÄ±mcÄ± olamÄ±yorum.\n\nSaÄŸlÄ±kla ilgili bir sorunuz varsa, lÃ¼tfen sorun!",
                    is_emergency=False
                )
    
    # 4. Pipeline: TR â†’ EN â†’ LLM â†’ EN â†’ TR
    
    # 4a. KullanÄ±cÄ± mesajÄ±nÄ± Ä°ngilizce'ye Ã§evir
    user_message_en = translate_to_english(user_message)
    
    # 4b. GeÃ§miÅŸ mesajlarÄ± Ä°ngilizce'ye Ã§evir
    messages_en = []
    for msg in request.history[-10:]:
        content_en = translate_to_english(msg.content) if msg.role == "user" else msg.content
        # Assistant mesajlarÄ± zaten Ä°ngilizce'den Ã§evrilmiÅŸ, tekrar Ã§evirmeye gerek yok
        # Ama basitlik iÃ§in hepsini Ã§evirelim
        if msg.role == "assistant":
            content_en = translate_to_english(msg.content)
        messages_en.append({"role": msg.role, "content": content_en})
    
    # KullanÄ±cÄ± mesajÄ±nÄ± ekle
    messages_en.append({"role": "user", "content": user_message_en})
    
    # 4c. Ä°ngilizce sistem prompt'u al (yapÄ±sal context ile)
    # has_health_context: True ise follow-up (kÄ±sa), False ise ilk saÄŸlÄ±k sorusu (detaylÄ±)
    system_prompt_en = get_english_system_prompt(
        detailed=request.detailed_response, 
        has_history=has_health_context,
        symptom_context=request.symptom_context
    )
    
    # 4d. Groq'tan Ä°ngilizce yanÄ±t al
    response_en = call_groq(messages_en, system_prompt=system_prompt_en)
    
    # 4e. YanÄ±tÄ± TÃ¼rkÃ§e'ye Ã§evir
    response_tr = translate_to_turkish(response_en)
    
    return ChatResponse(
        response=response_tr,
        is_emergency=False
    )


@app.get("/models")
async def list_models():
    return {
        "current_model": GROQ_MODEL,
        "available_models": [
            "llama-3.3-70b-versatile",
            "llama-3.1-70b-versatile", 
            "mixtral-8x7b-32768"
        ],
        "provider": "Groq",
        "pipeline": "TR â†’ EN â†’ LLM â†’ TR"
    }


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
