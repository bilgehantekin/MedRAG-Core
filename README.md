# ğŸ¥ Medical Chatbot - SaÄŸlÄ±k AsistanÄ±

TÃ¼rkÃ§e saÄŸlÄ±k odaklÄ± bilgilendirme chatbot'u. KullanÄ±cÄ±larÄ±n saÄŸlÄ±kla ilgili sorularÄ±nÄ± yanÄ±tlar, genel bilgi ve yÃ¶nlendirme saÄŸlar.

> âš ï¸ **Ã–nemli:** Bu bot teÅŸhis koymaz, sadece bilgilendirme ve yÃ¶nlendirme yapar.

## ğŸ¯ Ã–zellikler

- âœ… SaÄŸlÄ±k sorularÄ±nÄ± yanÄ±tlama
- âœ… SaÄŸlÄ±k dÄ±ÅŸÄ± sorularÄ± filtreleme
- âœ… Acil durum tespiti ve yÃ¶nlendirme
- âœ… DetaylÄ±/kÄ±sa yanÄ±t modu
- âœ… Modern chat arayÃ¼zÃ¼
- âœ… Lokal LLM desteÄŸi (Ollama)

## ğŸ“ Proje YapÄ±sÄ±

```
medical_chatbot/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py          # FastAPI ana uygulama
â”‚   â”‚   â”œâ”€â”€ health_filter.py # SaÄŸlÄ±k filtresi
â”‚   â”‚   â””â”€â”€ prompts.py       # LLM prompt ÅŸablonlarÄ±
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html           # Ana sayfa
â”‚   â”œâ”€â”€ styles.css           # Stiller
â”‚   â””â”€â”€ app.js               # JavaScript uygulamasÄ±
â””â”€â”€ README.md
```

## ğŸš€ Kurulum

### 1. Ollama Kurulumu (Lokal LLM)

```bash
# macOS
brew install ollama

# veya curl ile
curl -fsSL https://ollama.com/install.sh | sh
```

### 2. Model Ä°ndirme

```bash
# Ollama servisini baÅŸlat
ollama serve

# BaÅŸka bir terminalde model indir (Ã¶nerilen)
ollama pull llama3.2

# Alternatif modeller:
# ollama pull phi3
# ollama pull mistral
# ollama pull gemma2
```

### 3. Backend Kurulumu

```bash
cd backend

# Virtual environment oluÅŸtur
python3 -m venv venv
source venv/bin/activate  # macOS/Linux
# venv\Scripts\activate   # Windows

# BaÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kle
pip install -r requirements.txt
```

### 4. Backend'i Ã‡alÄ±ÅŸtÄ±r

```bash
cd backend
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

### 5. Frontend'i Ã‡alÄ±ÅŸtÄ±r

```bash
cd frontend

# Basit HTTP server ile
python3 -m http.server 3000

# veya
npx serve .
```

TarayÄ±cÄ±da aÃ§: http://localhost:3000

## ğŸ”§ YapÄ±landÄ±rma

### Ortam DeÄŸiÅŸkenleri

```bash
export OLLAMA_BASE_URL="http://localhost:11434"
export OLLAMA_MODEL="llama3.2"
```

### Frontend AyarlarÄ±

ArayÃ¼zdeki ayarlar butonundan:
- **DetaylÄ± YanÄ±tlar:** Daha kapsamlÄ± aÃ§Ä±klamalar iÃ§in
- **API Adresi:** Backend URL'ini deÄŸiÅŸtirmek iÃ§in

## ğŸ“¡ API Endpoints

### POST /chat

```json
{
  "message": "BaÅŸ aÄŸrÄ±sÄ± iÃ§in ne yapabilirim?",
  "history": [],
  "detailed_response": false
}
```

**YanÄ±t:**
```json
{
  "response": "BaÅŸ aÄŸrÄ±sÄ± iÃ§in...",
  "is_emergency": false,
  "disclaimer": "âš ï¸ Bu bilgiler eÄŸitim amaÃ§lÄ±dÄ±r..."
}
```

### GET /health
API saÄŸlÄ±k kontrolÃ¼

### GET /models
Mevcut Ollama modellerini listele

## ğŸ›¡ï¸ GÃ¼venlik Ã–zellikleri

1. **Domain Filtresi:** SaÄŸlÄ±k dÄ±ÅŸÄ± sorular reddedilir
2. **Acil Durum Tespiti:** Kritik semptomlar iÃ§in 112 yÃ¶nlendirmesi
3. **UyarÄ± MesajlarÄ±:** Her yanÄ±tta bilgilendirme disclaimeri
4. **TeÅŸhis Engeli:** LLM teÅŸhis koymamak Ã¼zere eÄŸitilmiÅŸ

## ğŸ¨ Ekran GÃ¶rÃ¼ntÃ¼leri

- Modern chat arayÃ¼zÃ¼
- Mesaj baloncuklarÄ± (kullanÄ±cÄ±/asistan)
- YazÄ±yor animasyonu
- Acil durum uyarÄ±larÄ±
- Mobil uyumlu tasarÄ±m

## ğŸ“ Lisans

MIT License

## ğŸ¤ KatkÄ±da Bulunma

1. Fork yapÄ±n
2. Feature branch oluÅŸturun (`git checkout -b feature/amazing-feature`)
3. Commit edin (`git commit -m 'Add amazing feature'`)
4. Push edin (`git push origin feature/amazing-feature`)
5. Pull Request aÃ§Ä±n

---

âš ï¸ **UyarÄ±:** Bu uygulama sadece bilgilendirme amaÃ§lÄ±dÄ±r. TÄ±bbi tavsiye yerine geÃ§mez. Acil durumlarda 112'yi arayÄ±n.
